
namespace KNNClassification
{
  internal class KNNClassificationProgram
  {
    public static void MainKNN(string[] args)
    {
      Console.WriteLine("\nBegin multi-class" +
        " classification predict politics using kNN ");

      // 1. load data
      Console.WriteLine("\nLoading People Dataset train" +
        " and test ");
      // 0.5, 0.25, 0.24, 0.25, 0, 0, 0, 0.2950, 2
      // 0.0, 0.75, 0.39, 0, 0, 0.25, 0, 0.5120, 1
      string trainFile =
        "..\\..\\..\\Data\\people_train_data.txt";
      double[][] trainX = Utils.MatLoad(trainFile,
        new int[] { 0, 1, 2, 3, 4, 5, 6, 7 }, ',', "#");
      int[] trainY =
        Utils.MatToIntVec(Utils.MatLoad(trainFile, [8],
        ',', "#"));

      string testFile = 
        "..\\..\\..\\Data\\people_test_data.txt";
      double[][] testX = Utils.MatLoad(testFile,
        new int[] { 0, 1, 2, 3, 4, 5, 6, 7 }, ',', "#");
      int[] testY =
        Utils.MatToIntVec(Utils.MatLoad(testFile, [8],
        ',', "#"));

      Console.WriteLine("\nFirst four training data: ");
      for (int i = 0; i < 4; ++i)
        Utils.VecShow(trainX[i], 4, 8);

      Console.WriteLine("\nFirst four target labels: ");
      for (int i = 0; i < 4; ++i)
        Console.Write(trainY[i] + " ");
      Console.WriteLine("");

      // 2. create model
      int C = 3;  // number classes
      KNN knn;    // k to be supplied later

      // try different k values
      Console.WriteLine("\nExamining different k values ");
      for (int k = 2; k < 7; ++k)
      {
        Console.WriteLine("\nk = " + k);
        knn = new KNN(C, k);
        knn.Train(trainX, trainY);
        double accTrain = knn.Accuracy(trainX, trainY);
        Console.WriteLine("Accuracy train = " +
          accTrain.ToString("F4"));
        double accTest = knn.Accuracy(testX, testY);
        Console.WriteLine("Accuracy test = " +
          accTest.ToString("F4"));
      }

      // 3. use model
      Console.WriteLine("\nUsing k = 5");
      knn = new KNN(C, 5);
      knn.Train(trainX, trainY);
      Console.WriteLine("\nConfusion matrix test data: \n");
      int[][] cm = knn.ConfusionMatrix(testX, testY);
      knn.ShowConfusion(cm);

      Console.WriteLine("\nPredicting for M tall 33" +
        " Colorado $65,000 ");
      double[] x = new double[] { 0.0, 0.75, 0.33,
        0, 0.25, 0, 0, 0.6500 };

      double[] pseudoProbs = knn.PredictProbs(x);
      Console.WriteLine("\nPredicted pseudo-probs: ");
      Utils.VecShow(pseudoProbs, 4, 8);

      int predY = knn.Predict(x);
      Console.WriteLine("\nPredicted class = " + predY);
      Console.WriteLine("(0 = conservative," +
        " 1 = moderate, 2 = liberal) ");

      Console.WriteLine("\nEnd demo ");
      Console.ReadLine();
    } // Main()

  } //class Program

  // =========================================================

  public class KNN
  {
    public int C;  // number classes
    public int k;  // number neighbors
    public double[][] trainX;
    public int[] trainY;

    public KNN(int C, int k)
    {
      this.C = C;
      this.k = k;
      this.trainX = new double[0][];  // keep compiler happy
      this.trainY = new int[0];
    }

    public void Train(double[][] trainX, int[] trainY)
    {
      this.trainX = trainX;  // by ref
      this.trainY = trainY;
    }

    public double[] PredictProbs(double[] x)
    {
      double[] result = new double[this.C];

      // compute distance between x and all trainX
      int n = this.trainX.Length;
      double[] distances = new double[n];
      for (int i = 0; i < n; ++i)
      {
        double d = EucDist(x, this.trainX[i]);
        distances[i] = d;
      }

      // sort distances and corresponding IDs
      int[] dataIDs = new int[n];
      for (int i = 0; i < n; ++i) { dataIDs[i] = i; }
      Array.Sort(distances, dataIDs); // parallel

      // determine majority class
      int[] counts = new int[this.C];
      for (int kk = 0; kk < this.k; ++kk)
      {
        int i = dataIDs[kk];
        int c = trainY[i];
        ++counts[c];
      }
      int maxCount = counts[0];
      int maxIdx = 0;  // the predicted class
      for (int i = 0; i < this.C; ++i)
      {
        if (counts[i] > maxCount)
        {
          maxCount = counts[i];
          maxIdx = i;
        }
      }

      // compute freq of each nearest class
      for (int i = 0; i < this.C; ++i)
        result[i] = (counts[i] * 1.0) / this.k;

      return result;
    }

    public int Predict(double[] x)
    {
      double[] probs = this.PredictProbs(x);
      int maxIdx = 0;
      double maxProb = probs[0];
      for (int i = 0; i < probs.Length; ++i)
      {
        if (probs[i] > maxProb)
        {
          maxProb = probs[i];
          maxIdx = i;
        }
      }
      return maxIdx;
    }

    private static double EucDist(double[] v1, double[] v2)
    {
      double sum = 0.0;
      for (int j = 0; j < v1.Length; ++j)
        sum += (v1[j] - v2[j]) * (v1[j] - v2[j]);
      return Math.Sqrt(sum);
    }

    public double Accuracy(double[][] dataX, int[] dataY)
    {
      int nCorrect = 0;
      int nWrong = 0;
      for (int i = 0; i < dataX.Length; ++i)
      {
        int c = this.Predict(dataX[i]);
        if (c == dataY[i])
          ++nCorrect;
        else
          ++nWrong;
      }
      return (nCorrect * 1.0) / (nCorrect + nWrong);
    }

    public int[][] ConfusionMatrix(double[][] dataX,
      int[] dataY)
    {
      int[][] result = new int[this.C][];
      for (int i = 0; i < this.C; ++i)
        result[i] = new int[this.C];
      for (int i = 0; i < dataX.Length; ++i)
      {
        int actualY = dataY[i];
        int predY = this.Predict(dataX[i]);
        ++result[actualY][predY];
      }
      return result;
    }

    public void ShowConfusion(int[][] cm)
    {
      int n = cm.Length;  // == this.C
      double[] accuracies = new double[n];
      for (int i = 0; i < n; ++i)
      {
        int rowSum = 0;
        for (int j = 0; j < n; ++j)
          rowSum += cm[i][j];
        accuracies[i] = (cm[i][i] * 1.0) / rowSum;
      }
      
      for (int i = 0; i < n; ++i)
      {
        Console.Write(" actual " +
          i.ToString().PadLeft(3) + " | ");
        for (int j = 0; j < n; ++j)
          Console.Write(cm[i][j].
            ToString().PadLeft(6));
        Console.WriteLine("  | " +
          accuracies[i].ToString("F4"));
      }
      Console.WriteLine("----------");
      Console.Write("predicted:    ");
      for (int j = 0; j < cm[0].Length; ++j)
        Console.Write(j.ToString().PadLeft(6));
      Console.WriteLine("");
    }

  } // class KNN

  // =========================================================

  public class Utils
  {
    // -------------------------------------------------------

    public static double[][] MatLoad(string fn,
     int[] usecols, char sep, string comment)
    {
      List<double[]> result = new List<double[]>();
      string line = "";
      FileStream ifs = new FileStream(fn, FileMode.Open);
      StreamReader sr = new StreamReader(ifs);
      while ((line = sr.ReadLine()) != null)
      {
        if (line.StartsWith(comment) == true)
          continue;
        string[] tokens = line.Split(sep);
        List<double> lst = new List<double>();
        for (int j = 0; j < usecols.Length; ++j)
          lst.Add(double.Parse(tokens[usecols[j]]));
        double[] row = lst.ToArray();
        result.Add(row);
      }
      sr.Close(); ifs.Close();
      return result.ToArray();
    }

    // -------------------------------------------------------

    public static int[] MatToIntVec(double[][] m)
    {
      // m is a column vec-mat
      int nRows = m.Length;
      int[] result = new int[nRows];
      for (int i = 0; i < nRows; ++i)
        result[i] = (int)m[i][0];
      return result;
    }

    // -------------------------------------------------------

    public static void MatShow(double[][] m,
      int dec, int wid)
    {
      double small = 1.0 / (Math.Pow(10.0, dec));
      for (int i = 0; i < m.Length; ++i)
      {
        for (int j = 0; j < m[0].Length; ++j)
        {
          double v = m[i][j];

          if (Math.Abs(v) < small) v = 0.0;  // avoid "-0"
          Console.Write(v.ToString("F" + dec).PadLeft(wid));
        }
        Console.WriteLine("");
      }
    }

    // -------------------------------------------------------

    public static void VecShow(double[] vec, int dec,
      int wid)
    {
      double small = 1.0 / (Math.Pow(10.0, dec));
      for (int i = 0; i < vec.Length; ++i)
      {
        double x = vec[i];
        if (Math.Abs(x) < small) x = 0.0;  // avoid "-0"
        Console.Write(x.ToString("F" + dec).PadLeft(wid));
      }
      Console.WriteLine("");
    }

    // -------------------------------------------------------

    public static void VecShow(int[] vec, int wid)
    {
      for (int i = 0; i < vec.Length; ++i)
        Console.Write(vec[i].ToString().PadLeft(wid));
      Console.WriteLine("");
    }

    // -------------------------------------------------------

  } // class Utils

} // ns

/*
 * 
# people_train.txt
# sex (M = 0, F = 0.5)
# height (short = 0.25, medium = 0.50, tall = 0.75)
# age (divided by 100)
# Arkansas = 0.25 0 0 0, Colorado = 0 0.25 0 0,
#  Delaware= 0 0 0.25 0, Illinois = 0 0 0 0.25
# income (divided by 100,000)
# conservative = 0, moderate = 1, liberal = 2
#
0.5, 0.25, 0.24, 0.25, 0.00, 0.00, 0.00, 0.2950, 2
0.0, 0.75, 0.39, 0.00, 0.00, 0.25, 0.00, 0.5120, 1
0.5, 0.25, 0.63, 0.00, 0.25, 0.00, 0.00, 0.7580, 0
0.0, 0.50, 0.36, 0.00, 0.00, 0.00, 0.25, 0.4450, 1
0.5, 0.25, 0.27, 0.00, 0.25, 0.00, 0.00, 0.2860, 2
0.5, 0.25, 0.50, 0.00, 0.25, 0.00, 0.00, 0.5650, 1
0.5, 0.50, 0.50, 0.00, 0.00, 0.00, 0.25, 0.5500, 1
0.0, 0.75, 0.19, 0.00, 0.00, 0.25, 0.00, 0.3270, 0
0.5, 0.25, 0.22, 0.00, 0.00, 0.00, 0.25, 0.2770, 1
0.0, 0.75, 0.39, 0.00, 0.00, 0.25, 0.00, 0.4710, 2
0.5, 0.25, 0.34, 0.25, 0.00, 0.00, 0.00, 0.3940, 1
0.0, 0.50, 0.22, 0.00, 0.00, 0.00, 0.25, 0.3350, 0
0.5, 0.50, 0.35, 0.00, 0.00, 0.25, 0.00, 0.3520, 2
0.0, 0.75, 0.33, 0.00, 0.25, 0.00, 0.00, 0.4640, 1
0.5, 0.25, 0.45, 0.00, 0.25, 0.00, 0.00, 0.5410, 1
0.5, 0.25, 0.42, 0.00, 0.00, 0.00, 0.25, 0.5070, 1
0.0, 0.75, 0.33, 0.00, 0.25, 0.00, 0.00, 0.4680, 1
0.5, 0.75, 0.25, 0.00, 0.00, 0.25, 0.00, 0.3000, 1
0.0, 0.50, 0.31, 0.00, 0.25, 0.00, 0.00, 0.4640, 0
0.5, 0.25, 0.27, 0.25, 0.00, 0.00, 0.00, 0.3250, 2
0.5, 0.25, 0.48, 0.00, 0.00, 0.00, 0.25, 0.5400, 1
0.0, 0.75, 0.64, 0.00, 0.00, 0.00, 0.25, 0.7130, 2
0.5, 0.50, 0.61, 0.00, 0.25, 0.00, 0.00, 0.7240, 0
0.5, 0.25, 0.54, 0.00, 0.00, 0.00, 0.25, 0.6100, 0
0.5, 0.25, 0.29, 0.25, 0.00, 0.00, 0.00, 0.3630, 0
0.5, 0.25, 0.50, 0.00, 0.00, 0.25, 0.00, 0.5500, 1
0.5, 0.50, 0.55, 0.00, 0.00, 0.00, 0.25, 0.6250, 0
0.5, 0.50, 0.40, 0.00, 0.00, 0.00, 0.25, 0.5240, 0
0.5, 0.25, 0.22, 0.25, 0.00, 0.00, 0.00, 0.2360, 2
0.5, 0.25, 0.68, 0.00, 0.25, 0.00, 0.00, 0.7840, 0
0.0, 0.75, 0.60, 0.00, 0.00, 0.00, 0.25, 0.7170, 2
0.0, 0.75, 0.34, 0.00, 0.00, 0.25, 0.00, 0.4650, 1
0.0, 0.50, 0.25, 0.00, 0.00, 0.25, 0.00, 0.3710, 0
0.0, 0.25, 0.31, 0.00, 0.00, 0.00, 0.25, 0.4890, 1
0.5, 0.25, 0.43, 0.00, 0.00, 0.25, 0.00, 0.4800, 1
0.5, 0.25, 0.58, 0.00, 0.25, 0.00, 0.00, 0.6540, 2
0.0, 0.75, 0.55, 0.00, 0.00, 0.00, 0.25, 0.6070, 2
0.0, 0.75, 0.43, 0.00, 0.25, 0.00, 0.00, 0.5110, 1
0.0, 0.75, 0.43, 0.00, 0.00, 0.25, 0.00, 0.5320, 1
0.0, 0.50, 0.21, 0.25, 0.00, 0.00, 0.00, 0.3720, 0
0.5, 0.25, 0.55, 0.00, 0.00, 0.25, 0.00, 0.6460, 0
0.5, 0.25, 0.64, 0.00, 0.25, 0.00, 0.00, 0.7480, 0
0.0, 0.75, 0.41, 0.00, 0.00, 0.00, 0.25, 0.5880, 1
0.5, 0.50, 0.64, 0.00, 0.00, 0.25, 0.00, 0.7270, 0
0.0, 0.50, 0.56, 0.00, 0.00, 0.00, 0.25, 0.6660, 2
0.5, 0.25, 0.31, 0.00, 0.00, 0.25, 0.00, 0.3600, 1
0.0, 0.75, 0.65, 0.00, 0.00, 0.25, 0.00, 0.7010, 2
0.5, 0.75, 0.55, 0.00, 0.00, 0.00, 0.25, 0.6430, 0
0.0, 0.25, 0.25, 0.25, 0.00, 0.00, 0.00, 0.4030, 0
0.5, 0.25, 0.46, 0.00, 0.00, 0.25, 0.00, 0.5100, 1
0.0, 0.75, 0.36, 0.00, 0.00, 0.00, 0.25, 0.5350, 0
0.5, 0.25, 0.52, 0.00, 0.00, 0.00, 0.25, 0.5810, 1
0.5, 0.25, 0.61, 0.00, 0.00, 0.25, 0.00, 0.6790, 0
0.5, 0.25, 0.57, 0.00, 0.00, 0.25, 0.00, 0.6570, 0
0.0, 0.75, 0.46, 0.00, 0.25, 0.00, 0.00, 0.5260, 1
0.0, 0.75, 0.62, 0.25, 0.00, 0.00, 0.00, 0.6680, 2
0.5, 0.25, 0.55, 0.00, 0.00, 0.00, 0.25, 0.6270, 0
0.0, 0.50, 0.22, 0.00, 0.00, 0.25, 0.00, 0.2770, 1
0.0, 0.75, 0.50, 0.00, 0.00, 0.00, 0.25, 0.6290, 0
0.0, 0.75, 0.32, 0.00, 0.00, 0.00, 0.25, 0.4180, 1
0.0, 0.25, 0.21, 0.00, 0.00, 0.25, 0.00, 0.3560, 0
0.5, 0.50, 0.44, 0.00, 0.25, 0.00, 0.00, 0.5200, 1
0.5, 0.25, 0.46, 0.00, 0.00, 0.00, 0.25, 0.5170, 1
0.5, 0.25, 0.62, 0.00, 0.25, 0.00, 0.00, 0.6970, 0
0.5, 0.25, 0.57, 0.00, 0.00, 0.00, 0.25, 0.6640, 0
0.0, 0.50, 0.67, 0.00, 0.00, 0.00, 0.25, 0.7580, 2
0.5, 0.25, 0.29, 0.25, 0.00, 0.00, 0.00, 0.3430, 2
0.5, 0.25, 0.53, 0.00, 0.00, 0.00, 0.25, 0.6010, 0
0.0, 0.75, 0.44, 0.25, 0.00, 0.00, 0.00, 0.5480, 1
0.5, 0.50, 0.46, 0.00, 0.25, 0.00, 0.00, 0.5230, 1
0.0, 0.75, 0.20, 0.00, 0.00, 0.00, 0.25, 0.3010, 1
0.0, 0.50, 0.38, 0.00, 0.00, 0.00, 0.25, 0.5350, 1
0.5, 0.25, 0.50, 0.00, 0.25, 0.00, 0.00, 0.5860, 1
0.5, 0.25, 0.33, 0.00, 0.25, 0.00, 0.00, 0.4250, 1
0.0, 0.75, 0.33, 0.00, 0.25, 0.00, 0.00, 0.3930, 1
0.5, 0.25, 0.26, 0.00, 0.25, 0.00, 0.00, 0.4040, 0
0.5, 0.25, 0.58, 0.25, 0.00, 0.00, 0.00, 0.7070, 0
0.5, 0.75, 0.43, 0.00, 0.00, 0.00, 0.25, 0.4800, 1
0.0, 0.50, 0.46, 0.25, 0.00, 0.00, 0.00, 0.6440, 0
0.5, 0.25, 0.60, 0.25, 0.00, 0.00, 0.00, 0.7170, 0
0.0, 0.75, 0.42, 0.25, 0.00, 0.00, 0.00, 0.4890, 1
0.0, 0.75, 0.56, 0.00, 0.00, 0.25, 0.00, 0.5640, 2
0.0, 0.25, 0.62, 0.00, 0.25, 0.00, 0.00, 0.6630, 2
0.0, 0.25, 0.50, 0.25, 0.00, 0.00, 0.00, 0.6480, 1
0.5, 0.25, 0.47, 0.00, 0.00, 0.00, 0.25, 0.5200, 1
0.0, 0.75, 0.67, 0.00, 0.25, 0.00, 0.00, 0.8040, 2
0.0, 0.75, 0.40, 0.00, 0.00, 0.25, 0.00, 0.5040, 1
0.5, 0.25, 0.42, 0.00, 0.25, 0.00, 0.00, 0.4840, 1
0.5, 0.25, 0.64, 0.25, 0.00, 0.00, 0.00, 0.7200, 0
0.0, 0.50, 0.47, 0.25, 0.00, 0.00, 0.00, 0.5870, 2
0.5, 0.50, 0.45, 0.00, 0.25, 0.00, 0.00, 0.5280, 1
0.0, 0.75, 0.25, 0.00, 0.00, 0.25, 0.00, 0.4090, 0
0.5, 0.25, 0.38, 0.25, 0.00, 0.00, 0.00, 0.4840, 0
0.5, 0.25, 0.55, 0.00, 0.00, 0.00, 0.25, 0.6000, 1
0.0, 0.75, 0.44, 0.25, 0.00, 0.00, 0.00, 0.6060, 1
0.5, 0.50, 0.33, 0.25, 0.00, 0.00, 0.00, 0.4100, 1
0.5, 0.25, 0.34, 0.00, 0.00, 0.25, 0.00, 0.3900, 1
0.5, 0.25, 0.27, 0.00, 0.25, 0.00, 0.00, 0.3370, 2
0.5, 0.25, 0.32, 0.00, 0.25, 0.00, 0.00, 0.4070, 1
0.5, 0.75, 0.42, 0.00, 0.00, 0.00, 0.25, 0.4700, 1
0.0, 0.25, 0.24, 0.00, 0.00, 0.25, 0.00, 0.4030, 0
0.5, 0.25, 0.42, 0.00, 0.25, 0.00, 0.00, 0.5030, 1
0.5, 0.25, 0.25, 0.00, 0.00, 0.25, 0.00, 0.2800, 2
0.5, 0.25, 0.51, 0.00, 0.25, 0.00, 0.00, 0.5800, 1
0.0, 0.50, 0.55, 0.00, 0.25, 0.00, 0.00, 0.6350, 2
0.5, 0.25, 0.44, 0.25, 0.00, 0.00, 0.00, 0.4780, 2
0.0, 0.25, 0.18, 0.25, 0.00, 0.00, 0.00, 0.3980, 0
0.0, 0.75, 0.67, 0.00, 0.25, 0.00, 0.00, 0.7160, 2
0.5, 0.25, 0.45, 0.00, 0.00, 0.25, 0.00, 0.5000, 1
0.5, 0.25, 0.48, 0.25, 0.00, 0.00, 0.00, 0.5580, 1
0.0, 0.25, 0.25, 0.00, 0.25, 0.00, 0.00, 0.3900, 1
0.0, 0.75, 0.67, 0.25, 0.00, 0.00, 0.00, 0.7830, 1
0.5, 0.25, 0.37, 0.00, 0.00, 0.25, 0.00, 0.4200, 1
0.0, 0.25, 0.32, 0.25, 0.00, 0.00, 0.00, 0.4270, 1
0.5, 0.25, 0.48, 0.25, 0.00, 0.00, 0.00, 0.5700, 1
0.0, 0.75, 0.66, 0.00, 0.00, 0.25, 0.00, 0.7500, 2
0.5, 0.75, 0.61, 0.25, 0.00, 0.00, 0.00, 0.7000, 0
0.0, 0.50, 0.58, 0.00, 0.00, 0.00, 0.25, 0.6890, 1
0.5, 0.25, 0.19, 0.25, 0.00, 0.00, 0.00, 0.2400, 2
0.5, 0.25, 0.38, 0.00, 0.00, 0.25, 0.00, 0.4300, 1
0.0, 0.50, 0.27, 0.25, 0.00, 0.00, 0.00, 0.3640, 1
0.5, 0.25, 0.42, 0.25, 0.00, 0.00, 0.00, 0.4800, 1
0.5, 0.25, 0.60, 0.25, 0.00, 0.00, 0.00, 0.7130, 0
0.0, 0.75, 0.27, 0.00, 0.00, 0.25, 0.00, 0.3480, 0
0.5, 0.75, 0.29, 0.00, 0.25, 0.00, 0.00, 0.3710, 0
0.0, 0.50, 0.43, 0.25, 0.00, 0.00, 0.00, 0.5670, 1
0.5, 0.50, 0.48, 0.25, 0.00, 0.00, 0.00, 0.5670, 1
0.5, 0.50, 0.27, 0.00, 0.00, 0.25, 0.00, 0.2940, 2
0.0, 0.75, 0.44, 0.25, 0.00, 0.00, 0.00, 0.5520, 0
0.5, 0.25, 0.23, 0.00, 0.25, 0.00, 0.00, 0.2630, 2
0.0, 0.75, 0.36, 0.00, 0.25, 0.00, 0.00, 0.5300, 2
0.5, 0.25, 0.64, 0.00, 0.00, 0.25, 0.00, 0.7250, 0
0.5, 0.25, 0.29, 0.00, 0.00, 0.00, 0.25, 0.3000, 2
0.0, 0.25, 0.33, 0.25, 0.00, 0.00, 0.00, 0.4930, 1
0.0, 0.75, 0.66, 0.00, 0.25, 0.00, 0.00, 0.7500, 2
0.0, 0.50, 0.21, 0.00, 0.00, 0.25, 0.00, 0.3430, 0
0.5, 0.25, 0.27, 0.25, 0.00, 0.00, 0.00, 0.3270, 2
0.5, 0.25, 0.29, 0.25, 0.00, 0.00, 0.00, 0.3180, 2
0.0, 0.75, 0.31, 0.25, 0.00, 0.00, 0.00, 0.4860, 1
0.5, 0.25, 0.36, 0.00, 0.00, 0.25, 0.00, 0.4100, 1
0.5, 0.25, 0.49, 0.00, 0.25, 0.00, 0.00, 0.5570, 1
0.0, 0.25, 0.28, 0.25, 0.00, 0.00, 0.00, 0.3840, 0
0.0, 0.50, 0.43, 0.00, 0.00, 0.25, 0.00, 0.5660, 1
0.0, 0.50, 0.46, 0.00, 0.25, 0.00, 0.00, 0.5880, 1
0.5, 0.25, 0.57, 0.25, 0.00, 0.00, 0.00, 0.6980, 0
0.0, 0.25, 0.52, 0.00, 0.00, 0.00, 0.25, 0.5940, 1
0.0, 0.75, 0.31, 0.00, 0.00, 0.25, 0.00, 0.4350, 1
0.0, 0.75, 0.55, 0.25, 0.00, 0.00, 0.00, 0.6200, 2
0.5, 0.25, 0.50, 0.25, 0.00, 0.00, 0.00, 0.5640, 1
0.5, 0.25, 0.48, 0.00, 0.25, 0.00, 0.00, 0.5590, 1
0.0, 0.50, 0.22, 0.00, 0.00, 0.25, 0.00, 0.3450, 0
0.5, 0.25, 0.59, 0.00, 0.00, 0.25, 0.00, 0.6670, 0
0.5, 0.25, 0.34, 0.25, 0.00, 0.00, 0.00, 0.4280, 2
0.0, 0.75, 0.64, 0.25, 0.00, 0.00, 0.00, 0.7720, 2
0.5, 0.25, 0.29, 0.00, 0.00, 0.25, 0.00, 0.3350, 2
0.0, 0.50, 0.34, 0.00, 0.25, 0.00, 0.00, 0.4320, 1
0.0, 0.50, 0.61, 0.25, 0.00, 0.00, 0.00, 0.7500, 2
0.5, 0.25, 0.64, 0.00, 0.00, 0.00, 0.25, 0.7110, 0
0.0, 0.25, 0.29, 0.25, 0.00, 0.00, 0.00, 0.4130, 0
0.5, 0.25, 0.63, 0.00, 0.25, 0.00, 0.00, 0.7060, 0
0.0, 0.50, 0.29, 0.00, 0.25, 0.00, 0.00, 0.4000, 0
0.0, 0.75, 0.51, 0.25, 0.00, 0.00, 0.00, 0.6270, 1
0.0, 0.75, 0.24, 0.00, 0.00, 0.25, 0.00, 0.3770, 0
0.5, 0.50, 0.48, 0.00, 0.25, 0.00, 0.00, 0.5750, 1
0.5, 0.25, 0.18, 0.25, 0.00, 0.00, 0.00, 0.2740, 0
0.5, 0.25, 0.18, 0.25, 0.00, 0.00, 0.00, 0.2030, 2
0.5, 0.25, 0.33, 0.00, 0.25, 0.00, 0.00, 0.3820, 2
0.0, 0.50, 0.20, 0.00, 0.00, 0.25, 0.00, 0.3480, 0
0.5, 0.25, 0.29, 0.00, 0.00, 0.25, 0.00, 0.3300, 2
0.0, 0.25, 0.44, 0.00, 0.00, 0.00, 0.25, 0.6300, 0
0.0, 0.75, 0.65, 0.00, 0.00, 0.25, 0.00, 0.8180, 0
0.0, 0.75, 0.56, 0.25, 0.00, 0.00, 0.00, 0.6370, 2
0.0, 0.50, 0.52, 0.00, 0.00, 0.25, 0.00, 0.5840, 1
0.0, 0.50, 0.29, 0.00, 0.25, 0.00, 0.00, 0.4860, 0
0.0, 0.75, 0.47, 0.00, 0.25, 0.00, 0.00, 0.5890, 1
0.5, 0.50, 0.68, 0.25, 0.00, 0.00, 0.00, 0.7260, 2
0.5, 0.25, 0.31, 0.00, 0.00, 0.25, 0.00, 0.3600, 1
0.5, 0.25, 0.61, 0.00, 0.25, 0.00, 0.00, 0.6250, 2
0.5, 0.25, 0.19, 0.00, 0.25, 0.00, 0.00, 0.2150, 2
0.5, 0.75, 0.38, 0.00, 0.00, 0.25, 0.00, 0.4300, 1
0.0, 0.75, 0.26, 0.25, 0.00, 0.00, 0.00, 0.4230, 0
0.5, 0.25, 0.61, 0.00, 0.25, 0.00, 0.00, 0.6740, 0
0.5, 0.25, 0.40, 0.25, 0.00, 0.00, 0.00, 0.4650, 1
0.0, 0.50, 0.49, 0.25, 0.00, 0.00, 0.00, 0.6520, 1
0.5, 0.50, 0.56, 0.25, 0.00, 0.00, 0.00, 0.6750, 0
0.0, 0.25, 0.48, 0.00, 0.25, 0.00, 0.00, 0.6600, 1
0.5, 0.25, 0.52, 0.25, 0.00, 0.00, 0.00, 0.5630, 2
0.0, 0.75, 0.18, 0.25, 0.00, 0.00, 0.00, 0.2980, 0
0.0, 0.75, 0.56, 0.00, 0.00, 0.00, 0.25, 0.5930, 2
0.0, 0.50, 0.52, 0.00, 0.25, 0.00, 0.00, 0.6440, 1
0.0, 0.50, 0.18, 0.00, 0.25, 0.00, 0.00, 0.2860, 1
0.0, 0.75, 0.58, 0.25, 0.00, 0.00, 0.00, 0.6620, 2
0.0, 0.75, 0.39, 0.00, 0.25, 0.00, 0.00, 0.5510, 1
0.0, 0.75, 0.46, 0.25, 0.00, 0.00, 0.00, 0.6290, 1
0.0, 0.50, 0.40, 0.00, 0.25, 0.00, 0.00, 0.4620, 1
0.0, 0.50, 0.60, 0.25, 0.00, 0.00, 0.00, 0.7270, 2
0.5, 0.25, 0.36, 0.00, 0.25, 0.00, 0.00, 0.4070, 2
0.5, 0.25, 0.44, 0.25, 0.00, 0.00, 0.00, 0.5230, 1
0.5, 0.25, 0.28, 0.25, 0.00, 0.00, 0.00, 0.3130, 2
0.5, 0.25, 0.54, 0.00, 0.00, 0.25, 0.00, 0.6260, 0
 * 
 */

/*
 * 
# people_test.txt
# sex, height, age, State, income, politics
#
0.0, 0.50, 0.51, 0.25, 0.00, 0.00, 0.00, 0.6120, 1
0.0, 0.25, 0.32, 0.00, 0.25, 0.00, 0.00, 0.4610, 1
0.5, 0.25, 0.55, 0.25, 0.00, 0.00, 0.00, 0.6270, 0
0.5, 0.25, 0.25, 0.00, 0.00, 0.25, 0.00, 0.2620, 2
0.5, 0.50, 0.33, 0.00, 0.00, 0.00, 0.25, 0.3730, 2
0.0, 0.50, 0.29, 0.00, 0.25, 0.00, 0.00, 0.4620, 0
0.5, 0.25, 0.65, 0.25, 0.00, 0.00, 0.00, 0.7270, 0
0.0, 0.75, 0.43, 0.00, 0.25, 0.00, 0.00, 0.5140, 1
0.0, 0.25, 0.54, 0.00, 0.25, 0.00, 0.00, 0.6480, 2
0.5, 0.25, 0.61, 0.00, 0.25, 0.00, 0.00, 0.7270, 0
0.5, 0.25, 0.52, 0.00, 0.25, 0.00, 0.00, 0.6360, 0
0.5, 0.25, 0.30, 0.00, 0.25, 0.00, 0.00, 0.3350, 2
0.5, 0.25, 0.29, 0.25, 0.00, 0.00, 0.00, 0.3140, 2
0.0, 0.75, 0.47, 0.00, 0.00, 0.25, 0.00, 0.5940, 1
0.5, 0.25, 0.39, 0.00, 0.25, 0.00, 0.00, 0.4780, 1
0.5, 0.25, 0.47, 0.00, 0.00, 0.00, 0.25, 0.5200, 1
0.0, 0.50, 0.49, 0.25, 0.00, 0.00, 0.00, 0.5860, 1
0.0, 0.75, 0.63, 0.00, 0.00, 0.25, 0.00, 0.6740, 2
0.0, 0.50, 0.30, 0.25, 0.00, 0.00, 0.00, 0.3920, 0
0.0, 0.75, 0.61, 0.00, 0.00, 0.00, 0.25, 0.6960, 2
0.0, 0.50, 0.47, 0.00, 0.00, 0.25, 0.00, 0.5870, 1
0.5, 0.25, 0.30, 0.00, 0.00, 0.00, 0.25, 0.3450, 2
0.0, 0.50, 0.51, 0.00, 0.00, 0.25, 0.00, 0.5800, 1
0.0, 0.50, 0.24, 0.25, 0.00, 0.00, 0.00, 0.3880, 1
0.0, 0.25, 0.49, 0.25, 0.00, 0.00, 0.00, 0.6450, 1
0.5, 0.50, 0.66, 0.00, 0.00, 0.00, 0.25, 0.7450, 0
0.0, 0.75, 0.65, 0.25, 0.00, 0.00, 0.00, 0.7690, 0
0.0, 0.25, 0.46, 0.00, 0.25, 0.00, 0.00, 0.5800, 0
0.0, 0.75, 0.45, 0.00, 0.00, 0.25, 0.00, 0.5180, 1
0.0, 0.25, 0.47, 0.25, 0.00, 0.00, 0.00, 0.6360, 0
0.0, 0.75, 0.29, 0.25, 0.00, 0.00, 0.00, 0.4480, 0
0.0, 0.75, 0.57, 0.00, 0.00, 0.00, 0.25, 0.6930, 2
0.0, 0.50, 0.20, 0.25, 0.00, 0.00, 0.00, 0.2870, 2
0.0, 0.50, 0.35, 0.25, 0.00, 0.00, 0.00, 0.4340, 1
0.0, 0.75, 0.61, 0.00, 0.00, 0.25, 0.00, 0.6700, 2
0.0, 0.25, 0.31, 0.00, 0.00, 0.00, 0.25, 0.3730, 1
0.5, 0.25, 0.18, 0.25, 0.00, 0.00, 0.00, 0.2080, 2
0.5, 0.50, 0.26, 0.00, 0.00, 0.25, 0.00, 0.2920, 2
0.0, 0.50, 0.28, 0.25, 0.00, 0.00, 0.00, 0.3640, 2
0.0, 0.75, 0.59, 0.00, 0.00, 0.00, 0.25, 0.6940, 2
 * 
 */
